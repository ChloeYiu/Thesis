\chapter{Conclusions and Future Work} \label{chap:conclusions}

This report investigates the use of Concept Activation Vectors (CAV) to measure bias in machine learning models, focusing on feature-based, text-based, and audio-based models. It examines how balanced weighting and CAV extraction methods influence results. Bias measurement with CAV is found to be most sensitive in feature-based models, particularly with L1 concepts, while factors like balanced weighting and CAV accuracy have minimal impact.

The gradient distance graph $\mathcal{B}^{(ci)}_{gr}$ is further analyzed. Feature-based models exhibit higher sensitivity to model bias. By isolating factors such as network architecture, model type, activation function, and input nature, it is found that LReLU activation functions narrow the lines plotted in the gradient distance graph, while ReLU widens them.

The investigation provides a deeper understanding of how the CAV method can measure bias in machine learning models and how factors such as model type, input nature, and CAV extraction methods influence results. The findings highlight CAV's sensitivity to feature-based models and the importance of considering activation functions when analyzing bias.

Future work should further investigate factors influencing CAV sensitivity, particularly the inconclusive impact of input nature, possibly due to short feature vectors compared to attention embeddings from the BERT encoder. Deep fusion with more balanced vector lengths could provide better insights. In addition, more combinations of network architectures could be used to further assess its impact to the sensitivity of CAVs.

Moreover, the underlying mechanisms behind how LReLU could flatten the gradient distance graph while ReLU widens it should be explored. This could involve a deeper analysis of how different activation functions interact with the model's architecture and input data, potentially leading to new insights into model behavior and bias sensitivity. Developing a theoretical framework to explain how the activation function shape these patterns would provide deeper insights into the behavior of CAVs.

Finally, the hypothesis that balanced weighting minimally affects bias sensitivity due to limited changes in CAV direction requires further testing. Future studies could rigorously measure CAV directions with and without balanced weighting.
